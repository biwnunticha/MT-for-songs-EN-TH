{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biwnunticha/MT-for-songs-EN-TH/blob/main/Fairseq_MT_(Songs).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U96IO9APGH_l"
      },
      "source": [
        "# Setup Libraries and Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBPKwPbhPDrR"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# W and B -- For Logging\n",
        "! pip install wandb\n",
        "\n",
        "# Sacremoses -- For Tokenizing\n",
        "! pip install sacremoses\n",
        "\n",
        "# fairseq -- For training and evaluation of the model\n",
        "! git clone https://github.com/pytorch/fairseq\n",
        "%cd fairseq\n",
        "! pip install --editable ./\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNO5MvAcHGsx",
        "outputId": "1cdb8918-8edb-412b-c77e-7b1daa778540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 20.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from fairseq) (0.12.1+cu113)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.12.1+cu113)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq) (4.64.1)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.6.0)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.0.6)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.0.7)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq) (0.29.32)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.3.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.10.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq) (4.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.10.0)\n",
            "Installing collected packages: fairseq\n",
            "Successfully installed fairseq-0.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install fairseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1akZY9xJ1_y",
        "outputId": "73c034ee-655a-46ce-b895-f0f9ff3f1a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting attacut\n",
            "  Downloading attacut-1.0.6-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 29.9 MB/s \n",
            "\u001b[?25hCollecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting nptyping>=0.2.0\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from attacut) (1.12.1+cu113)\n",
            "Requirement already satisfied: pyyaml>=5.1.2 in /usr/local/lib/python3.8/dist-packages (from attacut) (6.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from attacut) (1.15.0)\n",
            "Collecting ssg>=0.0.4\n",
            "  Downloading ssg-0.0.8-py3-none-any.whl (473 kB)\n",
            "\u001b[K     |████████████████████████████████| 473 kB 90.0 MB/s \n",
            "\u001b[?25hCollecting fire>=0.1.3\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from attacut) (1.21.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire>=0.1.3->attacut) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from nptyping>=0.2.0->attacut) (4.1.1)\n",
            "Collecting python-crfsuite>=0.9.6\n",
            "  Downloading python_crfsuite-0.9.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 86.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.8/dist-packages (from ssg>=0.0.4->attacut) (4.64.1)\n",
            "Building wheels for collected packages: docopt, fire\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=ac7ea797fb4d2f3f536e130bad87f9f5a29c016d99a291122f0084e4f6a0e0af\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=3e5b71a4af7c4de00860ae8d3aae005606a224d30213d0c94be29dd5095f5d78\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
            "Successfully built docopt fire\n",
            "Installing collected packages: python-crfsuite, fire, ssg, nptyping, docopt, attacut\n",
            "Successfully installed attacut-1.0.6 docopt-0.6.2 fire-0.4.0 nptyping-2.4.1 python-crfsuite-0.9.8 ssg-0.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install attacut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWtVRNMPo0ml"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pdb\n",
        "import pprint\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import tqdm.auto as tqdm\n",
        "from pathlib import Path\n",
        "from argparse import Namespace\n",
        "#from fairseq import utils\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7RJvQRpfXHZ",
        "outputId": "49232548-2e42-4d59-9007-54581ffdb4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pythainlp\n",
            "  Downloading pythainlp-3.1.1-py3-none-any.whl (9.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.6 MB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from pythainlp) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Installing collected packages: pythainlp\n",
            "Successfully installed pythainlp-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pythainlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RTi75pEe0iT",
        "outputId": "4ad3a137-7f38-472c-e1c9-969369bf0af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/MCFreddie777/language-check.git\n",
            "  Cloning https://github.com/MCFreddie777/language-check.git to /tmp/pip-req-build-em0q3w6v\n",
            "  Running command git clone -q https://github.com/MCFreddie777/language-check.git /tmp/pip-req-build-em0q3w6v\n",
            "Building wheels for collected packages: language-check\n",
            "  Building wheel for language-check (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for language-check: filename=language_check-1.1-py3-none-any.whl size=90190998 sha256=555d5879bed20b5dfc8b15c320c9e914ef3be6f3cbe0e26a23821d63fca83231\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ehf41tz1/wheels/c6/a8/a2/992f0138466a1425526af353678322a252aa8cbd0a6d93e2e7\n",
            "Successfully built language-check\n",
            "Installing collected packages: language-check\n",
            "Successfully installed language-check-1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/MCFreddie777/language-check.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLHvEXF5eGSW",
        "outputId": "a4102765-3d71-406a-d4da-da6fc0862446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 25.9 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 98.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehAvSb4uepup"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pythainlp\n",
        "import string\n",
        "import contractions\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNw_bFIHfiET"
      },
      "outputs": [],
      "source": [
        "from pythainlp.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1svxRO87Z2oGJ2k29AjeQ_iTf4luxXr0I\n",
        "!gdown --id 13iwodohZ4L18k5kIWh1mBs2r7VVvjqVf\n",
        "!gdown --id 14c4reG13pggu605Ouh4gQhfHM6ZM8HZk"
      ],
      "metadata": {
        "id": "e6RjZYsmFOTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "dev = pd.read_csv('dev.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "0EvP8jYQFvip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "id": "0kZIWM6wG4PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.rename(columns={'input_text':'lyrics', 'target_text':'tokenized'})\n",
        "dev = dev.rename(columns={'input_text':'lyrics', 'target_text':'tokenized'})"
      ],
      "metadata": {
        "id": "zWkduykuGJEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train.th', mode='w') as train_th:\n",
        "  for line in train['tokenized']:\n",
        "    line = str(line)\n",
        "    train_th.write(line.strip())\n",
        "    train_th.write('\\n')"
      ],
      "metadata": {
        "id": "GxRyRiIxtUnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgjb2GTWe2Sg"
      },
      "outputs": [],
      "source": [
        "with open('train.en', mode='w') as train_en:\n",
        "  for line in train['lyrics']:\n",
        "    line = str(line)\n",
        "    train_en.write(line.strip())\n",
        "    train_en.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FthuOqrme5qR"
      },
      "outputs": [],
      "source": [
        "with open('train.th', mode='w') as train_th:\n",
        "  for line in train['tokenized']:\n",
        "    line = str(line)\n",
        "    train_th.write(line.strip())\n",
        "    train_th.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTrADgLCe601"
      },
      "outputs": [],
      "source": [
        "with open('dev.en', mode='w') as dev_en:\n",
        "  for line in dev['lyrics']:\n",
        "    line = str(line)\n",
        "    dev_en.write(line.strip())\n",
        "    dev_en.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEGQb9vFe8Co"
      },
      "outputs": [],
      "source": [
        "with open('dev.th', mode='w') as dev_th:\n",
        "  for line in dev['tokenized']:\n",
        "    line = str(line)\n",
        "    dev_th.write(line.strip())\n",
        "    dev_th.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edl3lX8he9U5"
      },
      "outputs": [],
      "source": [
        "with open('test.en', mode='w') as test_en:\n",
        "  for line in test['lyrics']:\n",
        "    line = str(line)\n",
        "    test_en.write(line.strip())\n",
        "    test_en.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzjSTRZJe-0Q"
      },
      "outputs": [],
      "source": [
        "with open('test.th', mode='w') as test_th:\n",
        "  for line in test['tokenized']:\n",
        "    line = str(line)\n",
        "    test_th.write(line.strip())\n",
        "    test_th.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtPG1WlBGQ7w"
      },
      "source": [
        "## Pre-process and Binarize to build Vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OycGg77va6xt"
      },
      "outputs": [],
      "source": [
        "! fairseq-preprocess --source-lang en --target-lang th \\\n",
        "  --trainpref /content/train\\\n",
        "  --validpref  /content/dev\\\n",
        "  --testpref /content/test\\\n",
        "  --destdir data-bin/lyrics2022\\\n",
        "  --thresholdsrc 2 \\\n",
        "  --thresholdtgt 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCHShbvQGVfv"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RGvS-Yxb8C8"
      },
      "outputs": [],
      "source": [
        "! fairseq-train  'data-bin/lyrics2022'\\\n",
        "  --arch transformer \\\n",
        "  --dropout 0.1 \\\n",
        "  --attention-dropout 0.1 \\\n",
        "  --activation-dropout 0.1 \\\n",
        "  --encoder-embed-dim 256 \\\n",
        "  --encoder-ffn-embed-dim 512 \\\n",
        "  --encoder-layers 3 \\\n",
        "  --encoder-attention-heads 8 \\\n",
        "  --encoder-learned-pos \\\n",
        "  --decoder-embed-dim 256 \\\n",
        "  --decoder-ffn-embed-dim 512 \\\n",
        "  --decoder-layers 3 \\\n",
        "  --decoder-attention-heads 8 \\\n",
        "  --decoder-learned-pos \\\n",
        "  --max-epoch 10 \\\n",
        "  --optimizer adam \\\n",
        "  --lr 5e-4 \\\n",
        "  --batch-size 128 \\\n",
        "  --seed 1 \\\n",
        "  # --wandb-project \"Lyrics en to th Translation\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R52sr1X2GYuI"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4EbdJtHEHPz"
      },
      "outputs": [],
      "source": [
        "from sacrebleu import tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hf24_vOeZ6O"
      },
      "outputs": [],
      "source": [
        "# ckpt_best, beam=5\n",
        "! fairseq-generate data-bin/lyrics2022 \\\n",
        "    --path checkpoints/checkpoint_best.pt \\\n",
        "    --batch-size 128 \\\n",
        "    --beam 5 \\\n",
        "    --seed 1 \\\n",
        "    --scoring bleu \\\n",
        "    # --wandb-project \"Multi 30K En to De Translation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiQGHRyGfSY9"
      },
      "outputs": [],
      "source": [
        "# ckpt_best, beam=10\n",
        "! fairseq-generate data-bin/lyrics2022 \\\n",
        "    --path checkpoints/checkpoint_best.pt \\\n",
        "    --batch-size 128 \\\n",
        "    --beam 10 \\\n",
        "    --seed 1 \\\n",
        "    --scoring bleu \\\n",
        "    --quiet \\\n",
        "    # --wandb-project \"Multi 30K En to De Translation\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIt8meXUGiYf"
      },
      "source": [
        "# Generate Average Checkpoint (Ensemble)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_szOyTrh7dT"
      },
      "outputs": [],
      "source": [
        "!python fairseq/scripts/average_checkpoints.py --inputs checkpoints --num-epoch-checkpoints 5 --output checkpoints/averaged.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXUrAzfDiMpo"
      },
      "outputs": [],
      "source": [
        "# ckpt_avg, beam=5\n",
        "! fairseq-generate data-bin/lyrics2022 \\\n",
        "    --path checkpoints/averaged.pt \\\n",
        "    --batch-size 128 \\\n",
        "    --beam 5 \\\n",
        "    --seed 1 \\\n",
        "    --scoring bleu \\\n",
        "    --quiet \\\n",
        "    # --wandb-project \"Multi 30K En to De Translation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxUH5NcvDYAb"
      },
      "outputs": [],
      "source": [
        "# ckpt_avg, beam=10\n",
        "! fairseq-generate data-bin/lyrics2022 \\\n",
        "    --path checkpoints/averaged.pt \\\n",
        "    --batch-size 128 \\\n",
        "    --beam 10 \\\n",
        "    --seed 1 \\\n",
        "    --scoring bleu \\\n",
        "    --quiet \\\n",
        "    # --wandb-project \"Multi 30K En to De Translation\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F12YaRWtHSkQ"
      },
      "source": [
        "# Export the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opOQi-zmip5y"
      },
      "outputs": [],
      "source": [
        "! mkdir -p trained_model\n",
        "! cp data-bin/lyrics2022/dict.th.txt trained_model/dict.th.txt\n",
        "! cp data-bin/lyrics2022/dict.en.txt trained_model/dict.en.txt\n",
        "! cp checkpoints/averaged.pt trained_model/model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiSYhK0XHesc"
      },
      "outputs": [],
      "source": [
        "! fairseq-generate data-bin/lyrics2022 \\\n",
        "    --path checkpoints/averaged.pt \\\n",
        "    --batch-size 128 \\\n",
        "    --beam 5 \\\n",
        "    --seed 1 \\\n",
        "    --scoring bleu \\\n",
        "    --valid-subset valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2DDlFlTkwnf"
      },
      "outputs": [],
      "source": [
        "! fairseq-interactive \\\n",
        "  --path trained_model/model.pt \\\n",
        "  --source-lang en --target-lang th \\\n",
        "  --tokenizer moses \\\n",
        "  --task translation --cpu \\\n",
        "  --beam 5 \\\n",
        "  trained_model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hKZbH8hGfyC"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp9Ah6J5Gc96"
      },
      "outputs": [],
      "source": [
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0zSV3x5dU8r"
      },
      "outputs": [],
      "source": [
        "from fairseq.models.transformer import TransformerModel\n",
        "model = TransformerModel.from_pretrained(\n",
        "  '/content/trained_model',\n",
        "  checkpoint_file='model.pt',\n",
        "  source_lang='en',\n",
        "  target_lang='th'\n",
        "  #data_name_or_path='test.csv',\n",
        "  #bpe='fastbpe'\n",
        "  #bpe_codes=<bpe_file>\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwudGLobhFe7"
      },
      "outputs": [],
      "source": [
        "pred_list = []\n",
        "gold_list = []\n",
        "for index, lyrics in enumerate(test['lyrics']):\n",
        "  pred = model.translate(lyrics).replace(' ','')\n",
        "  pred_list.append(pred)\n",
        "  pred = pred.replace(' ', '').replace('▁', ' ').strip()\n",
        "  gold = test.iloc[index].tokenized.replace(' ','')\n",
        "  gold_list.append(gold)\n",
        "  input_sentence = lyrics\n",
        "  print('\\ninput_sentence:', input_sentence)\n",
        "  print('gold:', gold)\n",
        "  print('translation:', pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_list = test['lyrics'].tolist()"
      ],
      "metadata": {
        "id": "IA3YS0vhNSl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame({'input_text': test_list, 'predict': [x.replace(' ','').replace('<unk>','') for x in pred_list], 'gold': [x.replace(' ','').replace('<unk>','') for x in gold_list]})"
      ],
      "metadata": {
        "id": "1-Nmk-l6M8uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df"
      ],
      "metadata": {
        "id": "Gwechcj4PWHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.to_csv('fairseq_prediction.csv')"
      ],
      "metadata": {
        "id": "T6mr_tRiPq1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K4KdUNwl0yL"
      },
      "outputs": [],
      "source": [
        "pred_list[58]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPE-FRval5e9"
      },
      "outputs": [],
      "source": [
        "gold_list[58]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0hZGhlQi8gC"
      },
      "outputs": [],
      "source": [
        "chrf = evaluate.load(\"chrf\")\n",
        "results = chrf.compute(predictions=pred_list,references=gold_list,word_order=2,lowercase=True)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTPKLuNKPqVu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}